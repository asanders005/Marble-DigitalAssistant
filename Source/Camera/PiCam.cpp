#include "PiCam.h"

#include <core/buffer_sync.hpp>
#include <core/completed_request.hpp>
#include <core/frame_info.hpp>
#include <core/still_options.hpp>
#include <image/image.hpp>
#include <libcamera/camera_manager.h>

#include <atomic>
#include <fstream>
#include <iostream>
#include <memory>
#include <vector>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/imgproc.hpp>

// Code generated by GitHub Copilot, edited by Aiden Sanders

void PiCam::ConfigureStill(unsigned int width, unsigned int height, int quality)
{
    // set values into the camera's options (OptsInternal) via Options::Set()
    camera.GetOptions()->Set().width = width;
    camera.GetOptions()->Set().height = height;
    camera.GetOptions()->Set().encoding = "jpg";
    camera.GetOptions()->Set().quality = quality;
    camera.GetOptions()->Set().raw = false;      // Explicitly disable raw output
    camera.GetOptions()->Set().nopreview = true; // disable preview thread for headless operation

    // If an explicit camera isn't set in options, pick the first available libcamera camera.
    try
    {
        libcamera::CameraManager cm;
        cm.start();
        auto cams = cm.cameras();
        if (cams.size() == 0)
        {
            cm.stop();
            throw std::runtime_error("No libcamera cameras found");
        }
        // Set the camera index in options so RPiCamApp opens the correct device (use first camera)
        camera.GetOptions()->Set().camera = 0;
        cm.stop();
    }
    catch (const std::exception &e)
    {
        std::cerr << "Warning: could not auto-select camera: " << e.what() << "\n";
    }

    // Make a couple of explicit option choices to avoid invalid defaults
    camera.GetOptions()->Set().denoise = std::string("off");
    camera.GetOptions()->Set().metering = std::string("average");
    camera.GetOptions()->Set().awb = std::string("auto");

    // Open and start the camera once here so repeated captures don't re-enumerate devices.
    try
    {
        camera.OpenCamera();
        // Request BGR images (24bpp) rather than raw/YUV so jpeg_save receives RGB data
        camera.ConfigureStill(RPiCamApp::FLAG_STILL_BGR);
        camera.StartCamera();
        cameraRunning = true;
    }
    catch (const std::exception &e)
    {
        std::cerr << "Error opening/starting camera: " << e.what() << "\n";
        std::cerr << "Possible causes: requested resolution/format requires too large CMA buffers; "
                     "trying fallback resolution 640x480..."
                  << std::endl;
        // Try a smaller fallback resolution to succeed on systems with limited CMA
        try
        {
            // Ensure we clean up any partially-configured camera state
            try
            {
                camera.StopCamera();
            }
            catch (...)
            {
            }
            try
            {
                camera.CloseCamera();
            }
            catch (...)
            {
            }

            camera.GetOptions()->Set().width = 640;
            camera.GetOptions()->Set().height = 480;
            camera.OpenCamera();
            camera.ConfigureStill();
            camera.StartCamera();
            cameraRunning = true;
            stillConfigured = true;
            std::cerr << "Fallback to 640x480 succeeded." << std::endl;
        }
        catch (const std::exception &e2)
        {
            std::cerr << "Fallback failed: " << e2.what() << std::endl;
            std::cerr << "Either increase CMA memory in /boot/config.txt (cma=) or use a lower "
                         "resolution."
                      << std::endl;
            stillConfigured = false;
            return;
        }
    }

    stillConfigured = true;
}

void PiCam::ConfigureVideo(unsigned int width, unsigned int height, float framerate, int bitrate)
{
    // Use Set() to change the underlying OptsInternal members.
    encoder.GetOptions()->Set().width = width;
    encoder.GetOptions()->Set().height = height;
    encoder.GetOptions()->Set().framerate = static_cast<float>(framerate);
    encoder.GetOptions()->Set().bitrate.set(std::to_string(bitrate) + "bps");
    encoder.GetOptions()->Set().codec = "h264";

    videoConfigured = true;
}

void PiCam::CaptureStill(const std::string &outFile)
{
    if (!stillConfigured)
    {
        ConfigureStill(1920, 1080);
    }

    if (!cameraRunning)
    {
        // Defensive: ensure camera is running
        camera.OpenCamera();
        camera.ConfigureStill();
        camera.StartCamera();
        cameraRunning = true;
    }

    auto msg = camera.Wait();
    if (msg.type != RPiCamApp::MsgType::RequestComplete)
    {
        camera.StopCamera();
        camera.CloseCamera();
        throw std::runtime_error("Failed to capture still image.");
    }

    auto complete = std::get<CompletedRequestPtr>(msg.payload);

    RPiCamApp::Stream *imgStream = camera.StillStream(nullptr);
    if (!imgStream)
    {
        camera.StopCamera();
        camera.CloseCamera();
        throw std::runtime_error("Failed to get image stream.");
    }

    auto info = camera.GetStreamInfo(imgStream);

    BufferReadSync reader(&camera, complete->buffers[imgStream]);
    const auto &mem = reader.Get();

    // Debug: log plane counts and sizes to help diagnose empty/truncated JPEGs
    try
    {
        std::cerr << "CaptureStill: planes=" << mem.size() << "\n";
        for (size_t i = 0; i < mem.size(); ++i)
        {
            std::cerr << "  plane[" << i << "] size=" << mem[i].size() << "\n";
        }
    }
    catch (...)
    {
        std::cerr << "CaptureStill: failed to print plane sizes" << std::endl;
    }

    std::string outPath = "build/Assets/Images/" + outFile;
    try
    {
        jpeg_save(mem, info, complete->metadata, outPath, camera.CameraModel(),
                  static_cast<StillOptions const *>(camera.GetOptions()));
    }
    catch (const std::exception &e)
    {
        std::cerr << "jpeg_save threw: " << e.what() << std::endl;
    }
}

cv::Mat PiCam::CaptureToMat(bool saveDebugJPEG)
{
    if (!stillConfigured)
        ConfigureStill(1920, 1080);

    if (!cameraRunning)
    {
        camera.OpenCamera();
        camera.ConfigureStill(RPiCamApp::FLAG_STILL_BGR);
        camera.StartCamera();
        cameraRunning = true;
    }

    auto msg = camera.Wait();
    if (msg.type != RPiCamApp::MsgType::RequestComplete)
        throw std::runtime_error("Failed to capture still image.");

    auto complete = std::get<CompletedRequestPtr>(msg.payload);
    RPiCamApp::Stream *imgStream = camera.StillStream(nullptr);
    if (!imgStream)
        throw std::runtime_error("Failed to get image stream.");

    auto info = camera.GetStreamInfo(imgStream);
    BufferReadSync reader(&camera, complete->buffers[imgStream]);
    const auto &mem = reader.Get();

    if (mem.empty() || mem[0].size() == 0)
        throw std::runtime_error("Captured empty image buffer");

    // if (saveDebugJPEG)
    // {
    //     std::string outPath = "build/Assets/Images/debug.jpg";
    //     try
    //     {
    //         jpeg_save(mem, info, complete->metadata, outPath, camera.CameraModel(),
    //                   static_cast<StillOptions const *>(camera.GetOptions()));
    //     }
    //     catch (const std::exception &e)
    //     {
    //         std::cerr << "jpeg_save threw: " << e.what() << std::endl;
    //     }
    // }

    // Try to be robust to several possible pixel layouts. Prefer BGR if the stream
    // was requested with FLAG_STILL_BGR, but some pipelines may still return YUV.
    int w = info.width;
    int h = info.height;
    std::string fmt;
    try
    {
        fmt = info.pixel_format.toString();
    }
    catch (...)
    {
        fmt = "";
    }

    std::cerr << "CaptureToMat: pixel_format=" << fmt << " planes=" << mem.size() << "\n";

    // Case 1: already BGR888 in one plane
    if ((fmt.find("BGR") != std::string::npos || mem.size() == 1) && mem[0].size() >= static_cast<size_t>(w * h * 3))
    {
        size_t stride = info.stride ? info.stride : (w * 3);
        cv::Mat img(h, w, CV_8UC3, const_cast<uint8_t *>(mem[0].data()), stride);
        cv::Mat out = img.clone();
        if (saveDebugJPEG)
            cv::imwrite("build/Assets/Images/debug_from_mat.jpg", out);
        return out;
    }

    // Case 2: I420 / YUV420 planar (3 planes: Y, U, V) -> convert using OpenCV
    if (mem.size() >= 3)
    {
        size_t expectedY = static_cast<size_t>(w) * static_cast<size_t>(h);
        size_t expectedUV = (static_cast<size_t>(w) / 2) * (static_cast<size_t>(h) / 2);
        if (mem[0].size() >= expectedY && mem[1].size() >= expectedUV && mem[2].size() >= expectedUV)
        {
            std::vector<uint8_t> yuv;
            yuv.reserve(expectedY + expectedUV + expectedUV);
            yuv.insert(yuv.end(), mem[0].begin(), mem[0].begin() + expectedY);
            yuv.insert(yuv.end(), mem[1].begin(), mem[1].begin() + expectedUV);
            yuv.insert(yuv.end(), mem[2].begin(), mem[2].begin() + expectedUV);

            // Create a single-channel Mat of height + h/2 for I420 layout and convert
            cv::Mat yuvMat(static_cast<int>(h + h / 2), w, CV_8UC1, yuv.data());
            cv::Mat bgr;
            cv::cvtColor(yuvMat, bgr, cv::COLOR_YUV2BGR_I420);
            cv::Mat out = bgr.clone();
            if (saveDebugJPEG)
                cv::imwrite("build/Assets/Images/debug_from_i420.jpg", out);
            return out;
        }
    }

    // Case 3: NV12 (2 planes: Y, interleaved UV)
    if (mem.size() >= 2)
    {
        size_t expectedY = static_cast<size_t>(w) * static_cast<size_t>(h);
        size_t expectedUV = static_cast<size_t>(w) * static_cast<size_t>(h / 2);
        if (mem[0].size() >= expectedY && mem[1].size() >= expectedUV)
        {
            std::vector<uint8_t> yuv;
            yuv.reserve(expectedY + expectedUV);
            yuv.insert(yuv.end(), mem[0].begin(), mem[0].begin() + expectedY);
            yuv.insert(yuv.end(), mem[1].begin(), mem[1].begin() + expectedUV);

            cv::Mat yuvMat(static_cast<int>(h + h / 2), w, CV_8UC1, yuv.data());
            cv::Mat bgr;
            cv::cvtColor(yuvMat, bgr, cv::COLOR_YUV2BGR_NV12);
            cv::Mat out = bgr.clone();
            if (saveDebugJPEG)
                cv::imwrite("build/Assets/Images/debug_from_nv12.jpg", out);
            return out;
        }
    }

    // If none of the above worked, attempt a conservative row-wise copy from plane[0]
    try
    {
        size_t stride = info.stride ? info.stride : (w * 3);
        cv::Mat img(h, w, CV_8UC3);
        const uint8_t *src = mem[0].data();
        for (int r = 0; r < h; ++r)
        {
            const uint8_t *rowSrc = src + (size_t)r * stride;
            uint8_t *rowDst = img.ptr<uint8_t>(r);
            memcpy(rowDst, rowSrc, static_cast<size_t>(w * 3));
        }
        cv::Mat out = img.clone();
        if (saveDebugJPEG)
            cv::imwrite("build/Assets/Images/debug_from_guess.jpg", out);
        return out;
    }
    catch (const std::exception &e)
    {
        throw std::runtime_error(std::string("Unsupported/unknown capture format: ") + e.what());
    }
}

void PiCam::CaptureVideo(const std::string &outFile, int durationSeconds)
{
    if (!videoConfigured)
    {
        ConfigureVideo(1920, 1080);
    }

    // Open/Configure/Start
    encoder.OpenCamera();
    encoder.ConfigureVideo();
    encoder.StartCamera();

    // Hook to receive encoded output. encode callback receives (void* mem, size_t size, int64_ts,
    // bool eos)
    std::ofstream ofs("build/Assets/Videos/" + outFile, std::ios::binary);
    encoder.SetEncodeOutputReadyCallback(
        [&ofs](void *mem, size_t size, int64_t /*ts*/, bool /*eos*/)
        {
            if (mem && size)
                ofs.write(reinterpret_cast<char *>(mem), size);
        });

    // Create encoder internals and start encoding
    encoder.StartEncoder();

    // Run for durationSeconds, processing request-complete messages and asking the encoder
    auto start = std::chrono::steady_clock::now();
    while (
        std::chrono::duration_cast<std::chrono::seconds>(std::chrono::steady_clock::now() - start)
            .count() < durationSeconds)
    {
        auto msg = encoder.Wait();
        if (msg.type == RPiCamApp::MsgType::RequestComplete)
        {
            auto completed = std::get<CompletedRequestPtr>(msg.payload);
            // Get the video stream (RPiCamEncoder::VideoStream())
            RPiCamApp::Stream *video_stream = encoder.VideoStream(nullptr);
            if (video_stream)
            {
                // Ask encoder to encode this completed request (it will call your callback with
                // encoded bytes)
                bool started = encoder.EncodeBuffer(completed, video_stream);
                (void)started; // if false, the frame was skipped (e.g. sync not ready)
            }
        }
        else if (msg.type == RPiCamApp::MsgType::Quit)
        {
            break;
        }
    }

    // Stop encoder and camera
    encoder.StopEncoder();
    encoder.StopCamera();
    encoder.CloseCamera();
    ofs.close();
}

void PiCam::listCameras()
{
    libcamera::CameraManager cameraManager;
    cameraManager.start();
    auto cameraList = cameraManager.cameras();
    std::cout << "Available Cameras:\n";
    for (const auto &cam : cameraList)
    {
        std::cout << " - ID: " << cam->id() << ")\n";
    }
    cameraManager.stop();
}

PiCam::~PiCam()
{
    if (cameraRunning)
    {
        camera.StopCamera();
        camera.CloseCamera();
        cameraRunning = false;
    }
}

void PiCam::Shutdown()
{
    try
    {
        camera.StopCamera();
    }
    catch (...)
    {
    }
    try
    {
        camera.Teardown();
    }
    catch (...)
    {
    }
    try
    {
        camera.CloseCamera();
    }
    catch (...)
    {
    }
    cameraRunning = false;
}